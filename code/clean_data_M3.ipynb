{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Description\n",
    "Estimate the value of houses in Ames, Iowa, using 79 explanatory variables. The dataset is fairly small, with only 1460 training samples. The 79 features in the dataset are a mix of categorical and numerical features, and leave a lot of room for feature engineering.\n",
    "\n",
    "This notebook merely preprocesses the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set keggle on True if you want data for keggle competition\n",
    "# else leave on keggle on False for normal data\n",
    "keggle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('data/AmesHousing.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERVIEW\n",
    "\n",
    "There are multiple types of variables. Integers, floats, strings, NaN's. Use df.info() to gain detailed insight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display data information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2930 entries, numbered 0 to 2929, with **81 different features**. The **target feature** is 'SalePrice'. \n",
    "\n",
    "Out of all the columns there are several that have missing values. For instance, 'Alley', 'Pool QC', 'Fence', and 'Misc Feature'. These need to be fixed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the ourliers are checked by plotting the general living area with sale price, as is mentioned in the documentation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data['Gr Liv Area'], data['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garage year built is also plotted, since this shows also an outlier that is not possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the garage year built to show outliers\n",
    "sns.scatterplot(data['Garage Yr Blt'], data['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 ourliers visible that can be removed by removing datasamples with a general living area greater than 4000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['Gr Liv Area'] > 4000\n",
    "drop_sample = data[mask]\n",
    "data = data.drop(drop_sample.index, axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the value for the garage that is build after 2200 is replaces by NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['Garage Yr Blt'] > 2010\n",
    "outlier_garage = data['Garage Yr Blt'][mask]\n",
    "data['Garage Yr Blt'][outlier_garage.index] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column 'Order' since it is unique for each house\n",
    "clean_data = data.drop('Order', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical features who are classified as numeric features\n",
    "Some features in this dataset are stored as numeric data, but are actually categorical features. Therefore, the numeric data is converted into strings so they can be considered as categorical features.\n",
    "\n",
    "The only feature that is wrongly classified is: MS SubClass (the building class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[\"MS SubClass\"] = clean_data[\"MS SubClass\"].apply(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing ordinal categorical features to numerical features\n",
    "\n",
    "1. A function is made that can change ordinal categorical data to numerical features\n",
    "1. Dictonaries are created with the categories within features as keys and the corresponding numerical value as dictonary value\n",
    "3. Lists are created with the features that need to be replaced \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_to_num(lists, dicts):\n",
    "    \n",
    "    \"\"\"This function takes a list and a dictonary. \n",
    "    It replaces the categories in a feature to a nummerical \"\"\"\n",
    "    \n",
    "    # loop over the features in the list\n",
    "    for feature in lists:\n",
    "        \n",
    "        # replace the categories for the feature with the value of the dictonary\n",
    "        if feature in clean_data:\n",
    "            clean_data[feature] = clean_data[feature].map(dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list and dictonary for the most common categories\n",
    "common_ordinal_dict = {'Ex':5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "common_list_num_cats = ['Exter Qual', 'Exter Cond', 'Bsmt Cond', 'Heating QC', 'Kitchen Qual', 'Fireplace Qu', 'Garage Qual', 'Garage Cond', 'Bsmt Qual', 'Bsmt Qual']\n",
    "\n",
    "# change these to numerical features\n",
    "ordinal_to_num(common_list_num_cats, common_ordinal_dict)\n",
    "\n",
    "# create list and dict for Pool QC \n",
    "PoolQC_list = ['Pool QC']\n",
    "PoolQC_dict = {'Ex':4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'NA': 0}\n",
    "\n",
    "# execute the change for Pool QC\n",
    "ordinal_to_num(PoolQC_list, PoolQC_dict)\n",
    "\n",
    "# create list and dict for Land Slope\n",
    "slope_list = ['Land Slope']\n",
    "slope_dict = {'Gtl': 1, 'Mod': 2, 'Sev': 3}\n",
    "\n",
    "# execute the change for Land slope\n",
    "ordinal_to_num(slope_list, slope_dict)\n",
    "\n",
    "# create list and dict for Bsmt Exposure\n",
    "Bsmt_exposure_list = ['Bsmt Exposure']\n",
    "Bsmt_exposure_dict = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0}\n",
    "\n",
    "# execute the change for Bsmt Exposure\n",
    "ordinal_to_num(Bsmt_exposure_list, Bsmt_exposure_dict)\n",
    "\n",
    "# create list and dict of the types of finished basement\n",
    "bsmtFin_list = ['BsmtFin Type 1', 'BsmtFin Type 2']\n",
    "bsmtFin_dict = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0}\n",
    "\n",
    "# create list and dict of the types of unfinished basement\n",
    "ordinal_to_num(bsmtFin_list, bsmtFin_dict)\n",
    "\n",
    "display(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get overview of missing values\n",
    "clean_data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(df):\n",
    "    ''' Calculates and returns the percentage of missing data per feature. '''\n",
    "    percentage = 100 * df.isnull().sum() / len(df)\n",
    "    \n",
    "    # sort in ascending order\n",
    "    return percentage[percentage > 0].sort_values()\n",
    "\n",
    "percent_missing_data = missing_data(clean_data)\n",
    "\n",
    "sns.barplot(x = percent_missing_data.index, y = percent_missing_data)\n",
    "plt.title('Percentage of missing data per feature')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Percent of missing values (%)')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosing how to deal with missing values\n",
    "\n",
    "There are the following options/steps:\n",
    "\n",
    "1. Delete each row (sample) that contains a missing value\n",
    "2. Delete the whole column (feature) containing the missing values\n",
    "3. Replace the missing values with some other value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1**\n",
    "\n",
    "Delete each row(sample) that contains a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display rows that miss more than 1% of the data\n",
    "sns.barplot(x = percent_missing_data.index, y = percent_missing_data)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylim(0 , 1)\n",
    "\n",
    "# set labels\n",
    "plt.title('Percentage of missing data per feature')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Percent of missing values (%)')\n",
    "plt.show()\n",
    "\n",
    "if not keggle:\n",
    "    \n",
    "    # drop rows that miss less than 1% of the data\n",
    "    drop_rows = percent_missing_data[percent_missing_data <= 1]\n",
    "    drop_rows = drop_rows.index.tolist()\n",
    "    clean_data = clean_data.dropna(axis = 'index', subset = drop_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2**\n",
    "\n",
    "Delete the whole column (feature) containing the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features with more than 20% data missing\n",
    "drop_features = percent_missing_data[percent_missing_data >= 20]\n",
    "drop_features = drop_features.index.tolist()\n",
    "\n",
    "# remove those features\n",
    "clean_data = clean_data.drop(drop_features, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3**\n",
    "\n",
    "Replace the missing values with some other value. For **categorical data**, replace the missing value with 'none'.\n",
    "For **numerical data**, replace the missing value with the average value of that feature.\n",
    "\n",
    "First, single out the features that have missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features that have missing values between 1 and 20 percent missing data\n",
    "discuss_features = percent_missing_data[np.logical_and(percent_missing_data > 1, percent_missing_data < 20)]\n",
    "discuss_features = discuss_features.index.tolist()\n",
    "\n",
    "print(f\"The following features have missing values: {', '.join(discuss_features)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect each numeric feature seperately and decide how to best replace its missing values.\n",
    "\n",
    "**1. Lot Frontage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute means of lot frontage per neighborhood\n",
    "lot_means = clean_data.groupby('Neighborhood')['Lot Frontage'].mean()\n",
    "\n",
    "# replace missing values \n",
    "clean_data['Lot Frontage'] = clean_data.groupby('Neighborhood')['Lot Frontage'].transform(lambda val: val.fillna(val.mean()))\n",
    "\n",
    "# for GrHill use Timber mean since it is the closest\n",
    "clean_data[clean_data['Neighborhood'] == 'GrnHill'] = clean_data[clean_data['Neighborhood'] == 'GrnHill'].fillna(lot_means['Timber'])\n",
    "\n",
    "# for Landmrk use Old Town mean since it is the closes\n",
    "clean_data[clean_data['Neighborhood'] == 'Landmrk'] = clean_data[clean_data['Neighborhood'] == 'Landmrk'].fillna(lot_means['OldTown'])\n",
    "\n",
    "# remove lot frontage from features to be discussed\n",
    "discuss_features.remove('Lot Frontage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define difference between building years of house and garage\n",
    "dev = clean_data['Year Built'] - clean_data['Garage Yr Blt']\n",
    "# print(dev)\n",
    "# define the average difference\n",
    "avg_dev = np.round((dev.sum() / len(dev)), 0)\n",
    "\n",
    "print(avg_dev)\n",
    "\n",
    "# fill the nan values with the building year house with the avg deviation\n",
    "clean_data['Garage Yr Blt'] = clean_data['Garage Yr Blt'].fillna(clean_data['Year Built'] + avg_dev)\n",
    "\n",
    "print(clean_data['Garage Yr Blt'][2260])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other?** TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values\n",
    "def replace_values(df):\n",
    "    \"\"\"\n",
    "    This function replaces the missing values in the dataframe. If the missing\n",
    "    value is in a categorical feature, we replace the value for a 'None' string. \n",
    "    In this case, you can still use that feature. For the numeric features, we \n",
    "    replaced the missing values with the average number of that feature. \n",
    "    \n",
    "    \"\"\"\n",
    "    for feature in df:\n",
    "        \n",
    "        # single out categorical features and replace missing value with none\n",
    "        if clean_data.dtypes[feature] == object:\n",
    "            clean_data[feature] = clean_data[feature].fillna('None')\n",
    "\n",
    "        # single out numerical features and replace missing value with mean\n",
    "        else: \n",
    "            clean_data[feature] = clean_data[feature].fillna(clean_data[feature].mean())\n",
    "            \n",
    "    return clean_data\n",
    "        \n",
    "# check if all missing values are replaced\n",
    "clean_data = replace_values(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features\n",
    "\n",
    "**1. Price/square feet based on neighborhood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute price per square feet and add to data frame \n",
    "clean_data['Price/SF'] = clean_data['SalePrice'] / clean_data['Gr Liv Area']\n",
    "\n",
    "# compute average price per square feet per neighborhood\n",
    "avg_price = clean_data.groupby('Neighborhood')['Price/SF'].mean()\n",
    "\n",
    "# make dictionary from series\n",
    "avg_price = avg_price.to_dict()\n",
    "\n",
    "# replace values in price per sf column with average price per neighborhood\n",
    "clean_data['Price/SF'] = clean_data['Neighborhood'].map(avg_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Garden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['Garden Area'] = clean_data['Lot Area'] - (clean_data['Garage Area'] + clean_data['1st Flr SF'])\n",
    "display(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Age House**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['Age House'] = clean_data['Yr Sold'] - clean_data['Year Built']\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Total area house**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['Total House Area'] = clean_data['Total Bsmt SF'] + clean_data['Gr Liv Area']\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Total full bathrooms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['Total Full Bath'] = clean_data['Bsmt Full Bath'] + clean_data['Full Bath']\n",
    "display(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Total bathrooms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['Total Bath'] = clean_data['Full Bath'] + clean_data['Bsmt Full Bath'] + clean_data['Bsmt Half Bath'] + clean_data['Half Bath']\n",
    "\n",
    "display(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Average surface per neighborhood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_surface = clean_data.groupby('Neighborhood')['Gr Liv Area'].mean()\n",
    "\n",
    "# make dictionary from series\n",
    "avg_surface = avg_surface.to_dict()\n",
    "\n",
    "# replace values in price per sf column with average price per neighborhood\n",
    "clean_data['SF Difference'] = clean_data['Neighborhood'].map(avg_surface)\n",
    "\n",
    "clean_data['SF Difference'] = clean_data['Gr Liv Area'] - clean_data['SF Difference']\n",
    "\n",
    "display(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. inflation rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dummies from categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display feature data types in cleaned data\n",
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe in numerical and categorical\n",
    "cat_data = clean_data.select_dtypes(include = 'object')\n",
    "num_data = clean_data.drop(cat_data, axis=1)\n",
    "\n",
    "display(cat_data.head())\n",
    "display(num_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform categorical features to one-hot-encoding\n",
    "cat_data = pd.get_dummies(cat_data, drop_first=True)\n",
    "display(cat_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary remove houses unique ID's and target value Saleprice\n",
    "# because these should not be rescaled\n",
    "ID = num_data['PID']\n",
    "target = num_data['SalePrice']\n",
    "num_data = num_data.drop(['SalePrice', 'PID'], axis=1)\n",
    "\n",
    "# transform Sale Price in log Sale Price\n",
    "target = np.log10(target)\n",
    "\n",
    "# feature scale numerical data using zscore \n",
    "# note that we do not want to normalize our one-hot encoded data as those are already within [0,1] range\n",
    "# source: \"https://stackoverflow.com/a/41713622\"\n",
    "num_data = num_data.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge categorical and numerical dataframe\n",
    "num_data = pd.concat([num_data, target, ID], axis = 1)\n",
    "clean_data = pd.concat([cat_data, num_data], axis = 1)\n",
    "\n",
    "# display ditribution of data\n",
    "display(clean_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display info clean_data\n",
    "clean_data.info()\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data in test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training and test houses in clean_data with ID\n",
    "train_ID = train_data['PID'].to_numpy()\n",
    "test_ID = test_data['PID'].to_numpy()\n",
    "\n",
    "# split dataframe into test and train data\n",
    "train_data = clean_data[clean_data['PID'].isin(train_ID)]\n",
    "test_data = clean_data[clean_data['PID'].isin(test_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop PID's\n",
    "clean_data = clean_data.drop('PID', axis=1)\n",
    "num_data = num_data.drop('PID', axis=1)\n",
    "train_data = train_data.drop('PID', axis=1)\n",
    "test_data = test_data.drop('PID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export keggle cleaned train and test data to seperate csv file\n",
    "#export final cleaned dataframe to csv file  \n",
    "if keggle:\n",
    "    clean_data.to_csv('data/keggle_data.csv', index=False)  \n",
    "    train_data.to_csv('data/keggle_train_data.csv', index=False)\n",
    "    test_data.to_csv('data/keggle_test_data.csv', index=False)\n",
    "\n",
    "else:   \n",
    "    # export final cleaned dataframe to csv file\n",
    "    clean_data.to_csv('data/clean_data.csv', index=False)\n",
    "    train_data.to_csv('data/train_clean_data.csv', index=False)\n",
    "    test_data.to_csv('data/test_clean_data.csv', index=False)\n",
    "    \n",
    "    # export cleaned numerical and categorical data to seperate csv file\n",
    "    num_data.to_csv('data/num_clean_data.csv', index=False)\n",
    "    cat_data.to_csv('data/cat_clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

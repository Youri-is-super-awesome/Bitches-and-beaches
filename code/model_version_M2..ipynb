{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numerical data\n",
    "data_num = pd.read_csv('data/AmesHousingNumData.csv')\n",
    "\n",
    "# 'index=False' as parameter for exporting the files is a better solution\n",
    "data_num = data_num.drop('Unnamed: 0', axis=1) \n",
    "data_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split nummerical data in input and target\n",
    "target_num = data_num['SalePrice']\n",
    "final_data_num = data_num.drop('SalePrice', axis=1)\n",
    "\n",
    "# select the 2 most correlated features\n",
    "final_data_numSelect = data_num[['Gr Liv Area', 'Overall Qual']]\n",
    "\n",
    "display(final_data_numSelect.head())\n",
    "display(final_data_num.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import categorical data\n",
    "data_cat = pd.read_csv('data/AmesHousingCatData.csv')\n",
    "data_cat = data_cat.drop('Unnamed: 0', axis=1) \n",
    "\n",
    "# select the input and target from categorical data\n",
    "target_cat = data_cat['SalePrice']\n",
    "final_data_cat = data_cat.drop('SalePrice', axis=1)\n",
    "display(final_data_cat.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all data\n",
    "data_all = pd.read_csv('data/AmesHousingPreprocessed.csv')\n",
    "data_all = data_all.drop('Unnamed: 0', axis=1) \n",
    "\n",
    "# split data into input and target\n",
    "target_all = data_all['SalePrice']\n",
    "final_data_all = data_all.drop(['SalePrice', 'SalePrice.1'], axis=1)\n",
    "display(final_data_all.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, target, train_size = 0.7):\n",
    "    '''\n",
    "    convert the pandas dataframes to numpy ndarrays\n",
    "    '''\n",
    "    X_np = df.to_numpy()\n",
    "    y_np = target.to_numpy()\n",
    "    \n",
    "    # split the data into 70% training and 30% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, train_size=train_size, random_state=1265599650)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model\n",
    "\n",
    "#### Version 1: Multivariate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def calc_rmse(X_train, X_test, y_train, y_test, linear_model):\n",
    "    '''\n",
    "    Computes the Root mean squared error for the \n",
    "    '''\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    \n",
    "    predict = linear_model.predict(X_test)\n",
    "\n",
    "    linear_test_rmse = np.sqrt(mean_squared_error(y_test, predict))\n",
    "    \n",
    "    print(f'The test RMSE for our multivariate linear model is {linear_test_rmse}')\n",
    "\n",
    "    #print(f\"The theta values for our multivariate linear model are:\\n{linear_model.intercept_} and {linear_model.coef_}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Polynomial Regression Model\n",
    "\n",
    "Create new features from the existing ones. Check whether they add predictive value. \n",
    "\n",
    "1. Interaction Features\n",
    "\n",
    "= Generate a new feature from the product of two features. Represents the interaction effect between two variables on dependent variable. \n",
    "\n",
    "\n",
    "2. Polynomial Feature Expansion\n",
    "\n",
    "= Generate new features from the nth degree of each feature. \n",
    "\n",
    "Note: The second includes the first. The first is implemented to check whether including the interaction features alone improves the model or not. The second is implement to check whether features may have a non-linear relationship with the target feature.\n",
    "\n",
    "Taken from http://www.eamonfleming.com/projects/housing-regression.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2: Interaction Features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_interact(X_train, X_test, y_train, y_test, poly_model_interact):\n",
    "\n",
    "    # change feature matrix into polynomial feature matrix including interaction terms only\n",
    "    poly_interact = PolynomialFeatures(interaction_only=True)\n",
    "    X_train_interact = poly_interact.fit_transform(X_train)\n",
    "    X_test_interact = poly_interact.fit_transform(X_test)\n",
    "    \n",
    "    poly_model_interact.fit(X_train_interact, y_train)\n",
    "\n",
    "    predictions = poly_model_interact.predict(X_test_interact)\n",
    "\n",
    "    poly_test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "    print(f'The test RMSE for our interaction only polynomial model is {poly_test_rmse}')\n",
    "\n",
    "    #print(f'The theta values for the interact linear model are:\\n{poly_model_interact.coef_} and {poly_model_interact.intercept_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 3:  All Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_poly(X_train, X_test, y_train, y_test, poly_model, deg = 2):\n",
    "    \n",
    "    # change feature matrix into polynomial feature matrix\n",
    "    poly = PolynomialFeatures(degree = deg)\n",
    "    X_train_ = poly.fit_transform(X_train)\n",
    "    X_test_ = poly.fit_transform(X_test)\n",
    "\n",
    "    poly_model.fit(X_train_, y_train)\n",
    "\n",
    "    predictions = poly_model.predict(X_test_)\n",
    "\n",
    "    poly_test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "    print(f'The test RMSE for our polynomial model is {poly_test_rmse}')\n",
    "\n",
    "    #print(f'The theta values for our polynomial linear model are:\\n{poly_model.coef_} and {poly_model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and comparing the versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess(final_data_numSelect, target_num, train_size =0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'These are the outcomes for just a selection of the numerical data:\\n')\n",
    "\n",
    "linear_model_numSelect = LinearRegression()\n",
    "calc_rmse(X_train, X_test, y_train, y_test, linear_model_numSelect)\n",
    "\n",
    "poly_model_interact_numSelect = LinearRegression()\n",
    "poly_interact(X_train, X_test, y_train, y_test, poly_model_interact_numSelect)\n",
    "\n",
    "poly_model_numSelect = LinearRegression()\n",
    "add_poly(X_train, X_test, y_train, y_test, poly_model_numSelect, deg = 4)\n",
    "\n",
    "print(f'\\nDegree of 4 turned out to be the best degree if only 2 features are selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess(final_data_num, target_num, train_size =0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'These are the outcomes for all the numerical data:\\n')\n",
    "linear_model_num = LinearRegression()\n",
    "calc_rmse(X_train, X_test, y_train, y_test, linear_model_num)\n",
    "\n",
    "poly_model_interact_num = LinearRegression()\n",
    "poly_interact(X_train, X_test, y_train, y_test, poly_model_interact_num)\n",
    "\n",
    "poly_model_num = LinearRegression()\n",
    "add_poly(X_train, X_test, y_train, y_test, poly_model_num, deg = 2)\n",
    "\n",
    "print(f'\\nDegree of 2 was found to be the best fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'These are the outcomes for all the categorical data:\\n')\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess(final_data_cat, target_cat, train_size =0.7)\n",
    "\n",
    "linear_model_cat = LinearRegression()\n",
    "calc_rmse(X_train, X_test, y_train, y_test, linear_model_cat)\n",
    "\n",
    "poly_model_interact_cat = LinearRegression()\n",
    "poly_interact(X_train, X_test, y_train, y_test, poly_model_interact_cat)\n",
    "\n",
    "poly_model_cat = LinearRegression()\n",
    "add_poly(X_train, X_test, y_train, y_test, poly_model_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'These are the outcomes for all the combined data\\n')\n",
    "X_train, X_test, y_train, y_test = preprocess(final_data_all, target_all, train_size =0.7)\n",
    "\n",
    "linear_model_all = LinearRegression()\n",
    "calc_rmse(X_train, X_test, y_train, y_test, linear_model_all)\n",
    "\n",
    "poly_model_interact_all = LinearRegression()\n",
    "poly_interact(X_train, X_test, y_train, y_test, poly_model_interact_all)\n",
    "\n",
    "poly_model_all = LinearRegression()\n",
    "add_poly(X_train, X_test, y_train, y_test, poly_model_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Evaluate Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# only implement for all combined data\n",
    "X_train_ = poly.fit_transform(X_train)\n",
    "\n",
    "# add appropriate names to polynomial features\n",
    "X_train_ = pd.DataFrame(X_train_, columns = poly.get_feature_names(final_data_all.columns))\n",
    "\n",
    "# generate list of polynomial features and their correlations with sale price\n",
    "X_train_correlations = X_train_.corrwith(target_all)\n",
    "\n",
    "# sort features from highest positively correlated with sale price\n",
    "print('The highest positively correlated features with sale price are:')\n",
    "X_train_correlations.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort features from highest negatively correlated with sale price\n",
    "print('The highest negatively correlated features with sale price are:')\n",
    "X_train_correlations.sort_values().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial model for predicting Ames housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filename):\n",
    "    '''\n",
    "    Imports the given csv file. \n",
    "    '''\n",
    "    data = pd.read_csv(filename)\n",
    "    data = data.drop(['SalePrice'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "num_data = import_data('data/AmesHousingNumData.csv')\n",
    "print('Overview of numeric features')\n",
    "display(num_data.head())\n",
    "\n",
    "cat_data = import_data('data/AmesHousingCatData.csv')\n",
    "print('\\nOverview of categorical features')\n",
    "display(cat_data.head())\n",
    "\n",
    "all_data = import_data('data/AmesHousingPreprocessed.csv')\n",
    "print('\\nOverview of all features')\n",
    "display(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the 2 most correlated features\n",
    "final_data_numSelect = num_data[['Gr Liv Area', 'Overall Qual']]\n",
    "final_data_numSelect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe containing all data into input and target\n",
    "target = all_data['SalePrice.1']\n",
    "final_data_all = all_data.drop('SalePrice.1', axis=1)\n",
    "\n",
    "final_data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, target, train_size = 0.7):\n",
    "    '''\n",
    "    Converts the pandas dataframes to numpy ndarrays.\n",
    "    '''\n",
    "    X_np = df.to_numpy()\n",
    "    y_np = target.to_numpy()\n",
    "    \n",
    "    # split the data into 70% training and 30% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, train_size=train_size, random_state=1265599650)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "\n",
    "#### Version 1: Multivariate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def linear_model(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Computes a linear model for the given data and calculates the root mean squared error for that model.\n",
    "    '''\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    \n",
    "    # compute and store predictions for unseen feature values\n",
    "    predict = linear_model.predict(X_test)\n",
    "\n",
    "    # compute the root mean square error to evaluate performance\n",
    "    linear_test_rmse = np.sqrt(mean_squared_error(y_test, predict))\n",
    "    \n",
    "    print(f'The test RMSE for our multivariate linear model is {linear_test_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Polynomial Regression Model\n",
    "\n",
    "Create new features from the existing ones and check whether they add predictive value. \n",
    "\n",
    "- Interaction Features\n",
    "\n",
    "   Generate a new feature from the product of two features. Represents the interaction effect between two variablesondependent variable. \n",
    "\n",
    "\n",
    "- Polynomial Feature Expansion\n",
    "\n",
    "    Generate new features from the nth degree of each feature. \n",
    "\n",
    "Note: The second model includes the new interaction features as well. The first step is implemented to check whether including the interaction features alone improves the model or not. The second is implemented to check whether features may have a non-linear relationship with the target feature.\n",
    "\n",
    "Taken from http://www.eamonfleming.com/projects/housing-regression.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2: Interaction Features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_interact(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Builds and fits a polynomial model with only including interaction features. \n",
    "    Calculats and returns the rmse.\n",
    "    '''\n",
    "    # change feature matrix into polynomial feature matrix including interaction terms only\n",
    "    poly_interact = PolynomialFeatures(interaction_only=True)\n",
    "    X_train_interact = poly_interact.fit_transform(X_train)\n",
    "    X_test_interact = poly_interact.fit_transform(X_test)\n",
    "    \n",
    "    # fit the model\n",
    "    poly_model_interact = LinearRegression()\n",
    "    poly_model_interact.fit(X_train_interact, y_train)\n",
    "\n",
    "    # compute and store predictions for unseen feature values\n",
    "    predictions = poly_model_interact.predict(X_test_interact)\n",
    "\n",
    "    # compute the root mean square error to evaluate performance\n",
    "    poly_test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "    print(f'The test RMSE for our interaction only polynomial model is {poly_test_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 3:  All Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def poly_model(X_train, X_test, y_train, y_test, max_degree=6):\n",
    "    '''\n",
    "    Builds and fits a polynomial model including all features. Searches for the best degree\n",
    "    of the computed model and plots that degree. Returns the rmse of the best fit.\n",
    "    '''\n",
    "    rmses = []\n",
    "    min_rmse = 10\n",
    "    min_degree = None\n",
    "    \n",
    "    # test different degrees\n",
    "    degrees = range(1, max_degree)\n",
    "    for degree in degrees:\n",
    "        \n",
    "        # change feature matrix into polynomial feature matrix\n",
    "        poly = PolynomialFeatures(degree = degree)\n",
    "        X_train_ = poly.fit_transform(X_train)\n",
    "        X_test_ = poly.fit_transform(X_test)\n",
    "\n",
    "        poly_model = LinearRegression()\n",
    "        poly_model.fit(X_train_, y_train)\n",
    "\n",
    "        # compute and store predictions for unseen feature values\n",
    "        predictions = poly_model.predict(X_test_)\n",
    "\n",
    "        # compute the root mean square measure to evaluate performance\n",
    "        poly_test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        rmses.append(poly_test_rmse)\n",
    "        \n",
    "        # cross-validate degree\n",
    "        if poly_test_rmse < min_rmse:\n",
    "            min_rmse = poly_test_rmse\n",
    "            min_degree = degree\n",
    "   \n",
    "    print(f'The test RMSE for our polynomial model is {min_rmse}')\n",
    "\n",
    "    # plot results\n",
    "    plt.plot(degrees, rmses)\n",
    "\n",
    "    # layout\n",
    "    plt.title('Determine best degree')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('RMSE')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f'\\nThe best model fit for the polynomial model has degree {min_degree}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and comparing the versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only two numeric features to test the models\n",
    "X_train, X_test, y_train, y_test = preprocess(final_data_numSelect, target, train_size =0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'These are the outcomes when using two numerical features only:\\n')\n",
    "\n",
    "linear_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "poly_interact(X_train, X_test, y_train, y_test)\n",
    "\n",
    "poly_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all numeric data to test the models\n",
    "X_train, X_test, y_train, y_test = preprocess(num_data, target, train_size =0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'These are the outcomes for all the numerical data:\\n')\n",
    "\n",
    "linear_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "poly_interact(X_train, X_test, y_train, y_test)\n",
    "\n",
    "poly_model(X_train, X_test, y_train, y_test, max_degree=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Evaluate Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# only implement for all combined data\n",
    "X_train_ = poly.fit_transform(X_train)\n",
    "\n",
    "# add appropriate names to polynomial features\n",
    "X_train_ = pd.DataFrame(X_train_, columns = poly.get_feature_names(num_data.columns))\n",
    "\n",
    "# generate list of polynomial features and their correlations with sale price\n",
    "X_train_correlations = X_train_.corrwith(target)\n",
    "\n",
    "# sort features from highest positively correlated with sale price\n",
    "print('The highest positively correlated features with sale price are:')\n",
    "X_train_correlations.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort features from highest negatively correlated with sale price\n",
    "print('The highest negatively correlated features with sale price are:')\n",
    "X_train_correlations.sort_values().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "It was attempted to also test the models with categorical features as well as categorical and numerical features combined. Unfortunately, there seems to be a bug which results in very high RMSE values. Since the main goal - to examine whether there exist non-linear relationships between independent and dependent variabale - was achieved, it was deemed unnecessary to continue. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

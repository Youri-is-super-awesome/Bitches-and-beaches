{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8beefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import tensorflow.keras as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6550d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine list of features you want to check effect of on model accuracy\n",
    "# use format ['f1', 'f2', 'f3']\n",
    "# don't change if you want to check all features!\n",
    "list_features = []\n",
    "\n",
    "# determine number of best features you want to select in the data\n",
    "export_files = True\n",
    "keep_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "clean_data = pd.read_csv('data/preprocess_nodummies_data.csv')\n",
    "test_data = pd.read_csv('data/preprocess_nodummies_test_data.csv')\n",
    "train_data = pd.read_csv('data/preprocess_nodummies_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df):\n",
    "    \"\"\" transform categorical features to dummies with one-hot-encoding\n",
    "    Taken from https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\"\"\"\n",
    "\n",
    "    # select catagorical data from dataframe\n",
    "    cat_data = df.select_dtypes(include = 'object')\n",
    "    \n",
    "    # temporary remove categorical data from df\n",
    "    df = df.drop(cat_data, axis=1)\n",
    "    \n",
    "    # create dummies from categorical data\n",
    "    cat_data = pd.get_dummies(cat_data, drop_first=True)\n",
    "    \n",
    "    # merge cat data back into df\n",
    "    df = pd.concat([cat_data, df], axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, target, train_size = 0.7):\n",
    "    \n",
    "    \"\"\"convert the pandas dataframes to numpy ndarrays\"\"\"\n",
    "    df = create_dummies(df)\n",
    "    \n",
    "    X_np = df.to_numpy()\n",
    "    y_np = target.to_numpy()\n",
    "    \n",
    "    # split the data into 70% training and 30% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, train_size=train_size, random_state=1265599650)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76004d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NN(df, y, runs = 3, ep = 100): \n",
    "    \"\"\"Run neural network\"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = preprocess(df, target)\n",
    "    n_features = X_train.shape[1]\n",
    "\n",
    "    score = 0\n",
    "    \n",
    "    # run model i times\n",
    "    for i in range(runs):\n",
    "         \n",
    "        # create layers\n",
    "        model = tf.Sequential([\n",
    "            Dense(160),\n",
    "            Dense(224, activation='tanh'),\n",
    "            Dense(112, activation='tanh'),\n",
    "            Dense(240, activation='tanh'),\n",
    "            Dense(1, input_shape=(n_features,)),\n",
    "        ])    \n",
    "    \n",
    "        # compile model\n",
    "        metric = tf.metrics.RootMeanSquaredError()\n",
    "        model.compile(optimizer='Adam', loss=tf.metrics.mean_squared_error, metrics=[metric])  \n",
    "    \n",
    "        # run model for first number of epochs\n",
    "        model.fit(X_train, y_train, batch_size=64, epochs=ep, validation_data=(X_test, y_test))\n",
    "    \n",
    "        # compute RMSE of model \n",
    "        y_pred = model.predict(X_test)\n",
    "        score += metric(y_test,y_pred)\n",
    "    \n",
    "    score = score/runs\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run very simple neural network with all data\n",
    "target = clean_data['SalePrice']\n",
    "all_data = clean_data.drop(columns = ['SalePrice'])\n",
    "score = run_NN(all_data, target)\n",
    "print('Score of model with all data is:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a40ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "\n",
    "# select which features to check\n",
    "if list_features == []:\n",
    "    check_features = clean_data.drop(['SalePrice'], axis = 1) \n",
    "else:\n",
    "    check_features = clean_data[list_features]\n",
    "    \n",
    "# itterate over all features in check data\n",
    "for feature in check_features:\n",
    "    \n",
    "    # reset pop data to complete dataframe\n",
    "    pop_data = clean_data.drop(['SalePrice'], axis = 1)\n",
    "    \n",
    "    # remove 1 check feature\n",
    "    pop_data = pop_data.drop(columns = [feature])\n",
    "    \n",
    "    # run very simple neural network with pool data\n",
    "    score = run_NN(pop_data, target)\n",
    "    \n",
    "    # save score of nn and reoved feature in dict \n",
    "    accuracies[feature] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE of the model drops after bad feature is removed\n",
    "# sort RMSE of models from low to high to determine bad features\n",
    "d = accuracies\n",
    "d_list=sorted((value, key) for (key,value) in d.items())\n",
    "sortdict=dict([(k,v) for v,k in d_list])\n",
    "print(sortdict)\n",
    "\n",
    "# display features from good to bad (low to high RMSE) \n",
    "worst_features = list(sortdict.keys())\n",
    "\n",
    "# select bad features \n",
    "del worst_features[-keep_features:]                                    \n",
    "display(worst_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaff512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove worst features from dataframe\n",
    "for worst_feature in worst_features:\n",
    "    clean_data = clean_data.drop([worst_feature], axis = 1)\n",
    "    train_data = train_data.drop([worst_feature], axis = 1)\n",
    "    test_data = test_data.drop([worst_feature], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3073cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data with dummies\n",
    "clean_data = create_dummies(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9daef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_files:\n",
    "    # export final cleaned dataframe to csv file  \n",
    "    clean_data.to_csv('data/bestfeatures_data.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
